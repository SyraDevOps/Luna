# LunaGPT: Sistema de DiÃ¡logo Adaptativo e DinÃ¢mico

![Luna](img/Luna.png)

## SumÃ¡rio
- VisÃ£o Geral
- Arquitetura do Sistema
- Componentes Arquiteturais AvanÃ§ados
- InstalaÃ§Ã£o
- Guia de Uso
- Fluxo de Trabalho
- PreparaÃ§Ã£o de Dados
- OtimizaÃ§Ã£o de Performance
- Funcionalidades AvanÃ§adas
- Testes UnitÃ¡rios e Qualidade
- ResoluÃ§Ã£o de Problemas
- ContribuiÃ§Ã£o
- LicenÃ§a

## VisÃ£o Geral

LunaGPT Ã© um sistema de diÃ¡logo avanÃ§ado projetado para interaÃ§Ãµes dinÃ¢micas em portuguÃªs, com foco em adaptabilidade contextual e personalizaÃ§Ã£o. O sistema integra tÃ©cnicas de ponta em processamento de linguagem natural com uma arquitetura modular e expansÃ­vel.

### Principais Diferenciais

- **Arquitetura HÃ­brida**: CombinaÃ§Ã£o de transformers com camadas state-space e mixture of experts
- **Adaptabilidade DinÃ¢mica**: Ajuste em tempo real a diferentes perfis de hardware e requisitos de memÃ³ria
- **ContextualizaÃ§Ã£o Proativa**: Sistema de sugestÃµes baseado em padrÃµes de diÃ¡logo
- **Curriculum Learning**: Treinamento em estÃ¡gios progressivos para estabilidade e eficiÃªncia
- **RAG Integrado**: Enriquecimento contextual via recuperaÃ§Ã£o de documentos relevantes
- **Sistema de Feedback**: Aprendizado contÃ­nuo atravÃ©s de avaliaÃ§Ãµes de interaÃ§Ãµes

## Arquitetura do Sistema

### Estrutura de DiretÃ³rios

```
LunaGPT/
â”œâ”€â”€ data/                  # Datasets de treinamento e validaÃ§Ã£o
â”‚   â”œâ”€â”€ train/            # Arquivos de texto para treinamento
â”‚   â””â”€â”€ valid/            # Arquivos de texto para validaÃ§Ã£o
â”œâ”€â”€ logs/                  # Logs do sistema
â”œâ”€â”€ models/                # Checkpoints de modelos salvos
â”œâ”€â”€ src/                   # CÃ³digo-fonte
â”‚   â”œâ”€â”€ chat/             # Componentes de interface de chat
â”‚   â”‚   â”œâ”€â”€ luna_chat.py           # Interface principal de chat
â”‚   â”‚   â””â”€â”€ proactive_messenger.py # Sistema de sugestÃµes proativas
â”‚   â”œâ”€â”€ config/           # Sistema de configuraÃ§Ã£o
â”‚   â”‚   â””â”€â”€ config.py              # Classes de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ models/           # Arquitetura de modelo
â”‚   â”‚   â”œâ”€â”€ feedback_system.py     # Sistema de feedback
â”‚   â”‚   â”œâ”€â”€ growing_network.py     # Rede neural expansÃ­vel
â”‚   â”‚   â”œâ”€â”€ hypernet.py            # Hiperrede para geraÃ§Ã£o de parÃ¢metros
â”‚   â”‚   â”œâ”€â”€ luna_model.py          # Modelo principal
â”‚   â”‚   â”œâ”€â”€ moe.py                 # Mixture of Experts
â”‚   â”‚   â”œâ”€â”€ rag_retriever.py       # Sistema RAG
â”‚   â”‚   â””â”€â”€ tokenizer.py           # Tokenizador personalizado
â”‚   â”œâ”€â”€ tests/            # Testes unitÃ¡rios e integraÃ§Ã£o
â”‚   â”œâ”€â”€ training/         # Componentes de treinamento
â”‚   â”‚   â””â”€â”€ trainer.py             # Sistema de treinamento
â”‚   â””â”€â”€ utils/            # FunÃ§Ãµes utilitÃ¡rias
â”œâ”€â”€ feedback.jsonl         # Feedback coletado de usuÃ¡rios
â”œâ”€â”€ main.py                # Interface CLI principal
â””â”€â”€ setup.py               # Script de instalaÃ§Ã£o
```

### Core Components

- **LunaModel**: Rede neural principal com componentes avanÃ§ados (MoE, State-Space Layer, HyperNetwork)
- **LunaTokenizer**: Tokenizador customizado para texto em portuguÃªs com tratamento de tokens especiais
- **LunaTrainer**: Sistema de treinamento com suporte a curriculum learning e callbacks personalizados
- **LunaChat**: Interface de diÃ¡logo interativo com sistema proativo de sugestÃµes
- **RAGRetriever**: Sistema de recuperaÃ§Ã£o de documentos para enriquecimento contextual
- **FeedbackSystem**: Coleta e aplicaÃ§Ã£o de feedback para melhoria contÃ­nua

## Componentes Arquiteturais AvanÃ§ados

### 1. Arquitetura HÃ­brida e Modular

#### Mix of Experts (MoE) com Roteamento Emocional
```python
# Exemplo de uso do MoE
moe_block = MoEBlock(
    input_dim=768,
    num_experts=4,
    sparse_top_k=2,
    emotional_routing=True
)
output = moe_block(inputs, emotion_weights)
```

O MoE permite que diferentes "especialistas" (sub-redes neurais) sejam ativados seletivamente dependendo da entrada, aumentando a eficiÃªncia computacional. O roteamento emocional incorpora fatores como empatia, curiosidade e formalidade para direcionar quais especialistas sÃ£o utilizados.

#### HyperNetwork para GeraÃ§Ã£o DinÃ¢mica de ParÃ¢metros

```python
# Exemplo de uso do HyperNetwork
hypernet = HyperNetwork(context_dim=64, target_dim=768)
weight, bias = hypernet(context_vector)
```

A HyperNetwork gera parÃ¢metros para outras camadas condicionados ao contexto, permitindo adaptaÃ§Ã£o rÃ¡pida a diferentes domÃ­nios ou tipos de entrada.

#### GrowingNetwork para ExpansÃ£o durante Treinamento

```python
# Exemplo de uso do GrowingNetwork
growing_net = GrowingNetwork(base_model)
# ApÃ³s algum ponto do treinamento
if growing_net.should_grow(current_loss):
    growing_net.add_layer(input_dim=256, output_dim=256)
```

Esta inovaÃ§Ã£o permite que a rede neural cresÃ§a durante o treinamento, adicionando novas camadas conforme necessÃ¡rio para capturar mais capacidade quando o modelo atingir certos marcos.

#### State-Space Layer para DependÃªncias de Longo Alcance

```python
# Exemplo de uso do StateSpaceLayer
ssl = StateSpaceLayer(hidden_size=768, state_size=64)
output = ssl(input_sequence)
```

Camada inspirada em modelos state-space para modelagem eficiente de dependÃªncias de longo alcance em sequÃªncias, complementando o mecanismo de atenÃ§Ã£o dos transformers.

### 2. Pipeline de Treinamento AvanÃ§ado

#### Curriculum Learning MultistÃ¡gio

```python
# Exemplo de curriculum learning
stages = [
    {"context_length": 128, "batch_size": 16},
    {"context_length": 256, "batch_size": 8},
    {"context_length": 512, "batch_size": 4},
]
for stage in stages:
    trainer.train_supervised(train_data, valid_data, **stage)
```

Treinamento em estÃ¡gios progressivos, comeÃ§ando com sequÃªncias curtas e lotes maiores, e aumentando gradualmente a complexidade.

#### Callbacks Personalizados

- **CheckpointPTCallback**: Salva pesos em mÃºltiplos formatos
- **EarlyStoppingCallback**: Interrompe o treinamento quando a mÃ©trica de validaÃ§Ã£o nÃ£o melhora
- **DynamicHyperparamCallback**: Ajusta o learning rate em tempo real
- **MemoryReplayCallback**: Re-treina com exemplos de feedback de alta qualidade

### 3. Sistema RAG (Retrieval-Augmented Generation)

```python
# Exemplo de uso do RAG
retriever = RAGRetriever(embedding_dim=768)
retriever.add_documents(documents, metadatas)
relevant_docs = retriever.retrieve("Como funciona o LunaGPT?", top_k=3)
```

O sistema RAG recupera documentos relevantes para enriquecer o contexto do modelo durante a geraÃ§Ã£o de resposta, integrando conhecimento externo.

## InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8 ou superior
- GPU compatÃ­vel com CUDA (recomendado para treinamento)
- 8GB+ RAM (16GB+ recomendado)

### InstruÃ§Ãµes de Setup

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/seu-usuario/luna-project.git
   cd luna-project
   ```

2. Crie e ative um ambiente virtual:
   ```bash
   python -m venv Luna
   # No Windows
   Luna\Scripts\activate
   # No Linux/macOS
   source Luna/bin/activate
   ```

3. Instale as dependÃªncias:
   ```bash
   pip install -e .
   
   # Para instalar dependÃªncias para GPU
   pip install -e ".[gpu]"
   
   # Para instalar dependÃªncias de desenvolvimento
   pip install -e ".[dev]"
   ```

## Guia de Uso

### Interface de Linha de Comando

LunaGPT oferece uma interface de comando com vÃ¡rias operaÃ§Ãµes:

### CriaÃ§Ã£o de Modelo

```bash
python main.py create --name MODEL_NAME [--train_data PATH_PATTERN [PATH_PATTERN ...]]
```

**Exemplos**:

```bash
# Criar modelo com texto de amostra padrÃ£o
python main.py create --name LunaGPT-v1

# Criar modelo com dados personalizados
python main.py create --name LunaGPT-v1 --train_data "data/train/*.txt" "extra_data/*.json" "docs/*.pdf"
```

### Treinamento

```bash
python main.py train --model MODEL_NAME [--epochs NUM_EPOCHS] [--train_data PATH_PATTERN [PATH_PATTERN ...]] [--valid_data PATH_PATTERN [PATH_PATTERN ...]] [--use_wandb] [--lightweight]
```

**Exemplos**:

```bash
# Treinamento bÃ¡sico
python main.py train --model LunaGPT-v1

# Treinamento com opÃ§Ãµes personalizadas
python main.py train --model LunaGPT-v1 --epochs 5 --train_data "custom_data/*.txt" --use_wandb

# Treinamento em mÃ¡quina com recursos limitados
python main.py train --model LunaGPT-v1 --lightweight
```

### Chat Interativo

```bash
python main.py chat --model MODEL_NAME [--context INITIAL_CONTEXT] [--persona {tecnico,casual,formal}] [--device {auto,cpu,cuda,mps}]
```

**Exemplos**:

```bash
# Chat bÃ¡sico
python main.py chat --model LunaGPT-v1

# Chat com persona formal e contexto inicial
python main.py chat --model LunaGPT-v1 --persona formal --context "Bom dia, preciso de ajuda com um projeto."

# Chat forÃ§ando CPU (Ãºtil quando hÃ¡ problemas de memÃ³ria GPU)
python main.py chat --model LunaGPT-v1 --device cpu
```

### Refinamento com Feedback

```bash
python main.py refine --model MODEL_NAME [--lightweight] [--device {auto,cpu,cuda,mps}]
```

**Exemplos**:

```bash
# Refinamento bÃ¡sico
python main.py refine --model LunaGPT-v1

# Refinamento em hardware limitado
python main.py refine --model LunaGPT-v1 --lightweight --device cpu
```

### ExecuÃ§Ã£o de Testes

```bash
python main.py test [--minimal]
```

## Fluxo de Trabalho

### Fluxo Completo de Treinamento

```bash
# 1. Criar diretÃ³rios necessÃ¡rios
mkdir -p data/train data/valid

# 2. Adicionar dados de treinamento
echo "Este Ã© um exemplo de diÃ¡logo para treinar o modelo." > data/train/sample.txt
# Adicionar mais arquivos conforme necessÃ¡rio

# 3. Criar novo modelo
python main.py create --name MeuLunaGPT

# 4. Treinar modelo (com integraÃ§Ã£o Weights & Biases)
python main.py train --model MeuLunaGPT --epochs 3 --use_wandb

# 5. Interagir com o modelo treinado
python main.py chat --model MeuLunaGPT --persona casual

# 6. ApÃ³s coletar feedback, refinar o modelo
python main.py refine --model MeuLunaGPT
```

### Fluxo AvanÃ§ado com RAG

```bash
# 1. Criar e treinar o modelo base
python main.py create --name LunaRAG
python main.py train --model LunaRAG --epochs 3

# 2. Criar script para populaÃ§Ã£o do RAG
cat > populate_rag.py << 'EOL'
from src.models.rag_retriever import RAGRetriever
import glob

# Criar retriever
retriever = RAGRetriever(embedding_dim=768)

# Carregar documentos
documents = []
for file in glob.glob("knowledge_base/*.txt"):
    with open(file, 'r', encoding='utf-8') as f:
        documents.append(f.read())

# Adicionar documentos ao retriever
retriever.add_documents(documents)

# Salvar retriever
retriever.save("models/LunaRAG/retriever")
print(f"RAG populado com {len(documents)} documentos")
EOL

# 3. Executar script de populaÃ§Ã£o
python populate_rag.py

# 4. Interagir com o modelo enriquecido por RAG
python main.py chat --model LunaRAG
```

## PreparaÃ§Ã£o de Dados

### Formatos Suportados

O sistema suporta mÃºltiplos formatos de entrada:
- Arquivos de texto (.txt)
- CSV (.csv)
- JSON/JSONL (.json, .jsonl)
- Documentos PDF (.pdf)
- Microsoft Word (.docx)

### Exemplo de Dados de Treinamento

```
UsuÃ¡rio: OlÃ¡, como posso usar o LunaGPT?
Luna: OlÃ¡! VocÃª pode usar o LunaGPT atravÃ©s da interface de linha de comando. Basta executar "python main.py chat --model [nome-do-modelo]" para iniciar uma conversa.

UsuÃ¡rio: Quais sÃ£o os recursos avanÃ§ados do LunaGPT?
Luna: O LunaGPT possui vÃ¡rios recursos avanÃ§ados, como Mixture of Experts, State-Space Layers, HyperNetwork e RAG para enriquecimento contextual. Essas tecnologias permitem respostas mais precisas e adaptÃ¡veis.
```

### Data Augmentation

O sistema pode realizar augmentaÃ§Ã£o automÃ¡tica de dados, incluindo:
- ReordenaÃ§Ã£o sintÃ¡tica
- SubstituiÃ§Ã£o por sinÃ´nimos
- AdiÃ§Ã£o de variaÃ§Ãµes de estilo

## OtimizaÃ§Ã£o de Performance

### ConfiguraÃ§Ãµes para Hardware Limitado

```bash
# Treinamento em hardware limitado
python main.py train --model MeuLunaGPT --lightweight --device cpu

# Chat em hardware limitado
python main.py chat --model MeuLunaGPT --lightweight --device cpu
```

### QuantizaÃ§Ã£o e CompressÃ£o

O LunaGPT implementa automaticamente tÃ©cnicas de quantizaÃ§Ã£o dinÃ¢mica e poda (pruning) para reduzir o tamanho do modelo e acelerar a inferÃªncia:

```python
# A quantizaÃ§Ã£o Ã© aplicada automaticamente em hardware limitado
# Para forÃ§ar quantizaÃ§Ã£o em hardware potente:
config.model.force_quantization = True

# Para ajustar o nÃ­vel de quantizaÃ§Ã£o:
config.model.quantization_bits = 8  # 8, 4 ou 2 bits
```

### Monitoramento com Weights & Biases

```bash
# Treinar com integraÃ§Ã£o WandB
python main.py train --model MeuLunaGPT --use_wandb
```

## Funcionalidades AvanÃ§adas

### Sistema de Personas

LunaGPT suporta trÃªs personas principais que afetam o estilo de resposta:

- **tecnico**: Respostas detalhadas, precisas e objetivas
- **casual**: Tom conversacional, amigÃ¡vel e informal
- **formal**: Linguagem profissional, estruturada e educada

```bash
# Alternar entre personas
python main.py chat --model MeuLunaGPT --persona tecnico
python main.py chat --model MeuLunaGPT --persona casual
python main.py chat --model MeuLunaGPT --persona formal
```

### Proatividade Contextual

O sistema detecta padrÃµes de conversaÃ§Ã£o como:

- IndecisÃ£o: "nÃ£o sei", "talvez", "estou em dÃºvida"
- SolicitaÃ§Ãµes de ajuda: "como funciona", "preciso de ajuda"
- Busca de informaÃ§Ãµes: "onde posso encontrar", "procurar por"

E oferece sugestÃµes proativas para auxiliar o usuÃ¡rio:

```
UsuÃ¡rio: NÃ£o sei qual modelo de LunaGPT eu deveria usar para o meu projeto.

[SugestÃ£o]: Posso explicar mais detalhes para te ajudar a decidir?
```

### Curriculum Learning

```bash
# Script para treinamento com curriculum
cat > train_curriculum.py << 'EOL'
from src.config.config import Config
from src.training.trainer import LunaTrainer

config = Config()
trainer = LunaTrainer("MeuLunaGPT", config)

# Definir estÃ¡gios do curriculum
stages = [
    {"context_length": 64, "batch_size": 32, "epochs": 1},
    {"context_length": 128, "batch_size": 16, "epochs": 2},
    {"context_length": 256, "batch_size": 8, "epochs": 2}
]

# Carregar dados
train_data = [...] # seus dados de treinamento
valid_data = [...] # seus dados de validaÃ§Ã£o

# Treinar com curriculum
for i, stage in enumerate(stages):
    print(f"Iniciando estÃ¡gio {i+1}/{len(stages)}")
    config.training.per_device_train_batch_size = stage["batch_size"]
    config.training.max_position_embeddings = stage["context_length"]
    config.training.num_train_epochs = stage["epochs"]
    trainer.train_supervised(train_data, valid_data)
EOL
```

## Testes UnitÃ¡rios e Qualidade

### Executando Testes

```bash
# Executar todos os testes
python main.py test

# Executar testes com configuraÃ§Ãµes mÃ­nimas (para hardware limitado)
python main.py test --minimal

# Executar um mÃ³dulo de teste especÃ­fico
python -m unittest src.tests.test_chat
```

### Cobertura de Testes

O sistema inclui testes abrangentes para todos os componentes:

- **Arquitetura**: MoEBlock, HyperNetwork, GrowingNetwork, StateSpaceLayer
- **TokenizaÃ§Ã£o**: Treinamento, configuraÃ§Ã£o de tokens especiais
- **Modelo**: CriaÃ§Ã£o, salvamento, carregamento
- **Chat**: Resposta, extraÃ§Ã£o, personas
- **RAG**: IndexaÃ§Ã£o, recuperaÃ§Ã£o
- **Pipeline**: Treinamento completo, feedback, refinamento
- **Proatividade**: DetecÃ§Ã£o de padrÃµes, sugestÃµes contextuais

## ResoluÃ§Ã£o de Problemas

### Erros Comuns de CriaÃ§Ã£o de Modelo

**Erro**: `'LunaModel' object has no attribute 'save_pretrained'`

**SoluÃ§Ã£o**: A API foi atualizada para usar `save()` em vez de `save_pretrained()`. Verifique se estÃ¡ usando a versÃ£o mais recente.

### Erros de Treinamento

**Erro**: `'TrainingConfig' object has no attribute 'num_train_epochs'`

**SoluÃ§Ã£o**: Verifique a classe TrainingConfig em config.py para garantir que tenha o atributo `num_train_epochs`.

### Problemas de MemÃ³ria

**Erro**: "CUDA out of memory"

**SoluÃ§Ã£o**:
- Use a flag `--lightweight` para configuraÃ§Ãµes otimizadas
- Force CPU com `--device cpu`
- Reduza `batch_size` e aumente `gradient_accumulation_steps`

### Problemas de DependÃªncias

**Error**: "No module named 'faiss'"

**SoluÃ§Ã£o**:
```bash
pip install faiss-cpu
# OU para suporte GPU
pip install faiss-gpu
```

## ContribuiÃ§Ã£o

1. Fork o repositÃ³rio e crie um branch para sua feature
2. Siga o estilo de cÃ³digo existente
3. Adicione testes para novas funcionalidades
4. Atualize a documentaÃ§Ã£o conforme necessÃ¡rio
5. Envie um pull request com uma descriÃ§Ã£o clara das mudanÃ§as

### PadrÃ£o de Commit

```
[COMPONENT] Brief description

Detailed explanation of changes
```

Exemplo:
```
[MoE] Add emotional routing capability

- Implement emotion embedding layer
- Add support for emotion-conditioned routing
- Update tests for the new functionality
```

## LicenÃ§a

Este projeto estÃ¡ licenciado sob MIT License - consulte o arquivo LICENSE para detalhes.

---

Desenvolvido com ðŸ’™ pelo time Syra.

Para questÃµes ou suporte, abra uma issue no repositÃ³rio do projeto.